{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Third Party Imports\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Local imports\n",
    "import bat\n",
    "from bat import log_to_dataframe\n",
    "from bat import dataframe_to_matrix\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully monitoring /home/dane/giant/dns.log...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas dataframe from a Bro log\n",
    "bro_df = log_to_dataframe.LogToDataFrame('/home/dane/bro_logs/dns.log')\n",
    "\n",
    "# Print out the head of the dataframe\n",
    "bro_df.head()\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Using Pandas we can easily and efficiently compute additional data metrics\n",
    "# Here we use the vectorized operations of Pandas/Numpy to compute query length\n",
    "bro_df['query_length'] = bro_df['query'].str.len()\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNS records are a mix of numeric and categorical data\n",
    "When we look at the dns records some of the data is numerical and some of it is categorical so we'll need a way of handling both data types in a generalized way. bat has a DataFrameToMatrix class that handles a lot of the details and mechanics of combining numerical and categorical data, we'll use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# These are the features we want (note some of these are categorical :)\n",
    "features = ['AA', 'RA', 'RD', 'TC', 'Z', 'rejected', 'proto', 'query', \n",
    "            'qclass_name', 'qtype_name', 'rcode_name', 'query_length']\n",
    "feature_df = bro_df[features]\n",
    "feature_df.head()\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float: right; margin: -10px 40px -10px 40px\"><img src=\"images/transformers.png\" width=\"200px\"></div>\n",
    "## Transformers\n",
    "**We'll now use a bat scikit-learn tranformer class to convert the Pandas DataFrame to a numpy ndarray (matrix). Yes it's awesome... I'm not sure it's Optimus Prime awesome.. but it's still pretty nice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing column proto to category...\n",
      "Changing column qclass_name to category...\n",
      "Changing column qtype_name to category...\n",
      "Changing column rcode_name to category...\n",
      "Normalizing column Z...\n",
      "Normalizing column query_length...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Use the bat DataframeToMatrix class (handles categorical data)\n",
    "# You can see below it uses a heuristic to detect category data. When doing\n",
    "# this for real we should explicitly convert before sending to the transformer.\n",
    "to_matrix = dataframe_to_matrix.DataFrameToMatrix()\n",
    "bro_matrix = to_matrix.fit_transform(feature_df)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['proto', 'qclass_name', 'qtype_name', 'rcode_name']\n",
      "{'Z': (0, 1), 'query_length': (1, 88)}\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Just showing that the class is tracking categoricals and normalization maps\n",
    "print(to_matrix.cat_columns)\n",
    "print(to_matrix.norm_map)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're ready for scikit-learn!\n",
    "# Just some simple stuff for this example, KMeans and TSNE projection\n",
    "kmeans = KMeans(n_clusters=5).fit_predict(bro_matrix)\n",
    "projection = TSNE().fit_transform(bro_matrix)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can put our ML results back onto our dataframe!\n",
    "bro_df['tsne_0'] = projection[:, 0] # Projection X Column\n",
    "bro_df['tsne_1'] = projection[:, 1] # Projection Y Column\n",
    "bro_df['cluster'] = kmeans\n",
    "bro_df[['query', 'proto', 'tsne_0', 'tsne_1', 'cluster']].head()  # Showing the scikit-learn results in our dataframe\n",
    "# Plotting defaults\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 12.0\n",
    "plt.rcParams['figure.figsize'] = 15.0, 7.0\n",
    "# Now use dataframe group by cluster\n",
    "cluster_groups = bro_df.groupby('cluster')\n",
    "\n",
    "# Plot the Machine Learning results\n",
    "fig, ax = plt.subplots()\n",
    "colors = {0:'green', 1:'blue', 2:'red', 3:'orange', 4:'purple',}\n",
    "for key, group in cluster_groups:\n",
    "    group.plot(ax=ax, kind='scatter', x='tsne_0', y='tsne_1', alpha=0.01, s=2000,\n",
    "               label='Cluster: {:d}'.format(key), color=colors[key])\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now print out the details for each cluster\n",
    "pd.set_option('display.width', 1000)\n",
    "show_fields = ['query', 'Z', 'proto', 'qtype_name', \n",
    "               'cluster','AA', 'RA', 'RD',\n",
    "               'TC', 'rejected','qclass_name',\n",
    "               'rcode_name', 'query_length']\n",
    "for key, group in cluster_groups:\n",
    "    print('\\nCluster {:d}: {:d} observations'.format(key, len(group)))\n",
    "    print(group[show_fields].head())\n",
    "print(len(bro_df))\n",
    "# Cluster 0 = normal query\n",
    "# Cluster 1 = successful dns query to the \"internet\" by an HP laserjet printer\n",
    "# Cluster 2 = blank query without query type and length of 1\n",
    "# Cluster 3 = normal successful dns query to the \"internet\"\n",
    "# Cluster 4 = variable query_length, successful dns query of type PTR - Reverse-lookup Pointer records (PTR Record)â€”allows a DNS resolver to provide an IP address and receive a hostname (reverse DNS lookup).\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, group in cluster_groups:\n",
    "    print('\\nCluster {:d}: {:d} observations'.format(key, len(group)))\n",
    "    print(group[show_fields])\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
